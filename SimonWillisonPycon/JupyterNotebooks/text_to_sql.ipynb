{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae101ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM conversations;\n",
      "[{'COUNT(*)': 6}]\n"
     ]
    }
   ],
   "source": [
    "import sqlite_utils\n",
    "import llm\n",
    "\n",
    "model = llm.get_model(\"gpt-4.1-mini\")\n",
    "\n",
    "def text_to_sql(db: sqlite_utils.Database, question: str) -> str:\n",
    "    \"\"\"Convert a prompt to SQL using the LLM.\"\"\"\n",
    "    prompt = \"Schema:\\n\\n{}\\n\\nQuestion:\\n\\n{}\".format(\n",
    "        db.schema, question\n",
    "    )\n",
    "    return model.prompt(\n",
    "        prompt,\n",
    "        system=\"reply with SQLite SQL, not in markdown, just the SQL\",\n",
    "    ).text()\n",
    "\n",
    "db = sqlite_utils.Database(llm.user_dir() / \"logs.db\")\n",
    "\n",
    "sql = text_to_sql(db, \"how many conversations are there?\")\n",
    "\n",
    "print(sql)\n",
    "\n",
    "# Now execute it\n",
    "result = db.query(sql)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94e756",
   "metadata": {},
   "source": [
    "# Upgrading that to a CLI tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba469ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--db DB] [--execute] question\n",
      "ipykernel_launcher.py: error: the following arguments are required: question\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/python-3.13-playground/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3680: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import sqlite_utils\n",
    "import llm\n",
    "\n",
    "# pick your model\n",
    "model = llm.get_model(\"gpt-4.1-mini\")\n",
    "\n",
    "def text_to_sql(db: sqlite_utils.Database, question: str) -> str:\n",
    "    \"\"\"Convert an English question into a SQLite SQL statement.\"\"\"\n",
    "    prompt = \"Schema:\\n\\n{}\\n\\nQuestion:\\n\\n{}\".format(db.schema, question)\n",
    "    resp = model.prompt(\n",
    "        prompt,\n",
    "        system=\"reply with SQLite SQL, not in markdown, just the SQL\",\n",
    "    )\n",
    "    return resp.text().strip()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Turn a natural-language question into SQL (and optionally run it).\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"question\",\n",
    "        help=\"The question to ask of your SQLite database, in plain English.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--db\",\n",
    "        \"-d\",\n",
    "        default=str(llm.user_dir() / \"logs.db\"),\n",
    "        help=\"Path to the SQLite database file.  [default: %(default)s]\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--execute\",\n",
    "        \"-x\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Execute the generated SQL and print the results instead of just showing the SQL.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    db_path = Path(args.db)\n",
    "    if not db_path.exists():\n",
    "        parser.error(f\"Database file not found: {db_path!r}\")\n",
    "\n",
    "    db = sqlite_utils.Database(db_path)\n",
    "    sql = text_to_sql(db, args.question)\n",
    "\n",
    "    if args.execute:\n",
    "        try:\n",
    "            rows = list(db.query(sql))\n",
    "        except Exception as e:\n",
    "            print(\"ERROR running SQL:\", e)\n",
    "            print(\"SQL was:\", sql)\n",
    "            raise SystemExit(1)\n",
    "        # print rows as simple CSV\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    else:\n",
    "        print(sql)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3416322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Spectacular Pelican', 'age': 5, 'short_bio': 'This pelican is known for its majestic wingspan that exceeds 8 feet, making it one of the largest birds in the world. It is often seen gliding gracefully over coastal waters and performing impressive dives to catch fish.', 'beak_capacity_ml': 800}\n"
     ]
    }
   ],
   "source": [
    "import llm, json\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Pelican(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    short_bio: str\n",
    "    beak_capacity_ml: float\n",
    "\n",
    "model = llm.get_model(\"gpt-4o-mini\")\n",
    "response = model.prompt(\"Describe a spectacular pelican\", schema=Pelican)\n",
    "pelican = json.loads(response.text())\n",
    "print(pelican)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53587565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
