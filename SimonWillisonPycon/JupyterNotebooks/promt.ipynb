{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1c2b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the walrus lose his shoes?\n",
      "\n",
      "Because he was too \"tusk\"-ed up to remember where he put them!\n"
     ]
    }
   ],
   "source": [
    "import llm\n",
    "model = llm.get_model(\"gpt-4.1-mini\")\n",
    "response = model.prompt(\n",
    "    \"A joke about a walrus who lost his shoes\"\n",
    ")\n",
    "print(response.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1d95d",
   "metadata": {},
   "source": [
    "# Using system Attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8784e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.prompt(\n",
    "    \"Describe this image\",\n",
    "    attachments=[\n",
    "        llm.Attachment(\n",
    "            url=\"https://static.simonwillison.net/static/2025/two-pelicans.jpg\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(response.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216f3ea",
   "metadata": {},
   "source": [
    "# Using system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e87dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ஒரு பெலிகானின் சிறந்த அம்சம் என்ன?\n"
     ]
    }
   ],
   "source": [
    "def translate_to_tamil(text):\n",
    "    model = llm.get_model(\"gpt-4.1-mini\")\n",
    "    response = model.prompt(\n",
    "        text,\n",
    "        system=\"Translate this to Tamil\"\n",
    "    )\n",
    "    return response.text()\n",
    "\n",
    "# And try it out:\n",
    "print(translate_to_tamil(\"What is the best thing about a pelican?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df3bc7",
   "metadata": {},
   "source": [
    "# Async support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835324d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28mprint\u001b[39m(chunk, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Or just print(await response.text())\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import llm\n",
    "\n",
    "model = llm.get_async_model(\"gpt-4.1-mini\")\n",
    "async def main():\n",
    "    response = model.prompt(\n",
    "        \"A joke about a walrus who lost his shoes\"\n",
    "    )\n",
    "    async for chunk in response:\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    # Or just print(await response.text())\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f574d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
